# E-Commerce Data Pipeline Project

**Student Name:** Bharghav Sai Marla  
**Roll Number:** 23P31A0503  

---

## ğŸ“Œ Project Overview
This project implements an end-to-end **data engineering pipeline** for an e-commerce analytics platform.  
It covers the complete lifecycle from **data generation â†’ ingestion â†’ transformation â†’ warehousing â†’ analytics â†’ BI dashboards**, following industry best practices.

---

## ğŸ› ï¸ Prerequisites

Ensure the following tools are installed before setup:

- **Python 3.8+**
- **PostgreSQL 12+**
- **Docker & Docker Compose**
- **Git**
- **Tableau Public OR Power BI Desktop (Free version)**

---

## âš™ï¸ Installation Steps

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/marlabharghavsai/ecommerce-data-pipeline-23P31A0503.git
cd ecommerce-data-pipeline-23P31A0503
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
docker-compose up -d

```

## Project Architecture

This project implements a complete end-to-end **data analytics pipeline** for an e-commerce platform, transforming raw transactional data into business insights through a dimensional data warehouse and BI dashboards.

### Data Flow Overview

```
Raw CSV Data
â†“
Staging Schema (PostgreSQL)
â†“
Production Schema (Cleaned & Validated)
â†“
Warehouse Schema (Star Schema)
â†“
Analytics Queries
â†“
BI Dashboard (Tableau / Power BI)

```

## Technology Stack

- **Data Generation:** Python (Faker)
- **Database:** PostgreSQL 14
- **ETL & Transformations:** Python (psycopg2, pandas)
- **Data Modeling:** Kimball Star Schema
- **Orchestration:** Custom Python Pipeline Orchestrator
- **Scheduling:** Python Scheduler
- **Monitoring & Alerting:** Python Monitoring Scripts
- **Containerization:** Docker & Docker Compose
- **Testing:** Pytest with Coverage
- **BI Visualization:** Tableau Public / Power BI Desktop

---

## Project Structure

```
ecommerce-data-pipeline/
â”œâ”€â”€ config/
â”‚ â””â”€â”€ config.yaml
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”œâ”€â”€ staging/
â”‚ â”œâ”€â”€ production/
â”‚ â””â”€â”€ processed/
â”œâ”€â”€ dashboards/
â”‚ â”œâ”€â”€ screenshots/
â”‚ â””â”€â”€ tableau/
â”œâ”€â”€ docs/
â”‚ â”œâ”€â”€ architecture.md
â”‚ â””â”€â”€ dashboard_guide.md
â”œâ”€â”€ logs/
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ data_generation/
â”‚ â”œâ”€â”€ ingestion/
â”‚ â”œâ”€â”€ transformation/
â”‚ â”œâ”€â”€ monitoring/
â”‚ â”œâ”€â”€ pipeline_orchestrator.py
â”‚ â”œâ”€â”€ scheduler.py
â”‚ â””â”€â”€ cleanup_old_data.py
â”œâ”€â”€ sql/
â”‚ â”œâ”€â”€ ddl/
â”‚ â””â”€â”€ queries/
â”œâ”€â”€ tests/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ pytest.ini
â””â”€â”€ README.md

```

## Running the Pipeline
- Full Pipeline Execution : python scripts/pipeline_orchestrator.py
  
### Individual Steps
- python scripts/data_generation/generate_data.py
- python scripts/ingestion/ingest_to_staging.py
- python scripts/quality_checks/validate_data.py
- python scripts/transformation/staging_to_production.py
- python scripts/transformation/load_warehouse.py
- python scripts/transformation/generate_analytics.py

### Running Tests
- pytest tests/ -v
- With coverage: pytest --cov=scripts --cov-report=term-missing
 
### Dashboard Access
- Tableau Public URL: https://public.tableau.com/app/profile/bharghav.sai.marla/vizzes
- Screenshots: dashboards/screenshots/

### Database Schemas
- Staging Schema
  - staging.customers
  - staging.products
  - staging.transactions
  - staging.transaction_items
- Production Schema
  - production.customers
  - production.products
  - production.transactions
  - production.transaction_items
- Warehouse Schema
  - warehouse.dim_customers
  - warehouse.dim_products
  - warehouse.dim_date
  - warehouse.dim_payment_method
  - warehouse.fact_sales
  - warehouse.agg_daily_sales
  - warehouse.agg_product_performance
  - warehouse.agg_customer_metrics

### Key Insights from Analytics
- Electronics category generates the highest revenue
- Strong revenue growth observed during Q4
- VIP customers contribute a disproportionate share of revenue
- Weekend sales outperform weekdays
- Online payment methods dominate transactions

### Challenges & Solutions

1.Duplicate warehouse loads
  - Solved using TRUNCATE + idempotent inserts
2.Data quality mismatches
  - Implemented reconciliation logic
3.Scheduler blocking tests
  - Used __main__ guards and test isolation
4.Timezone inconsistencies
  - Standardized all timestamps to UTC
5.Coverage failures
  - Added focused unit tests and import validation


### Future Enhancements
- Real-time streaming with Apache Kafka
- Cloud deployment on AWS/GCP
- Machine learning for demand forecasting
- Real-time alerting with Slack or Email
- Incremental warehouse loading

### Contact

- Name: Bharghav Sai
- Roll Number: 23P31A0503
- Email: marlabharghavsai@gmail.com



